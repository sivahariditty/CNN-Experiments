{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezNet_Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeIvNWH4bmM9IHoge/EgfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivahariditty/CNN-Experiments/blob/main/SqueezNet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uAlcZwMqjkZB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06U4qzzHneiF",
        "outputId": "4c62709e-a21a-460f-8b74-3ec67da40c0a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])"
      ],
      "metadata": {
        "id": "wWOXFIexn6yR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcb-jIuhsRY6",
        "outputId": "a8a83714-4969-4c9f-bf5c-be6e1711411e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG - 16"
      ],
      "metadata": {
        "id": "kkxdUL4iu3jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "T47fonDuu8UE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet = models.squeezenet1_0(pretrained=True)"
      ],
      "metadata": {
        "id": "KDEgSodJvosY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in sqnet.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "prUFB0rB1WS3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))"
      ],
      "metadata": {
        "id": "cJbBptCkwAqW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in sqnet.parameters():\n",
        "  if(param.requires_grad):\n",
        "    print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL7v5Vrq1O1S",
        "outputId": "7023f2ea-345f-42ad-c09d-2d7442dd2ab7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 512, 1, 1])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(dataloader,model):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "81x0f5Io4MhP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet = sqnet.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt=optim.SGD(sqnet.parameters(),lr=0.5)"
      ],
      "metadata": {
        "id": "V6gkitWwDqwG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n"
      ],
      "metadata": {
        "id": "QoQ72YN5MqZe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def train(model,traindata,epochs=1):\n",
        "  min_loss = 10000\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      for i, data in enumerate(traindata, 0):\n",
        "\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          opt.zero_grad()\n",
        "\n",
        "          outputs = sqnet(inputs)\n",
        "          loss = loss_fn(outputs, labels)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "          if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(sqnet.state_dict())\n",
        "            print(\"Min loss : %0.2f\"%min_loss)\n",
        "          \n",
        "          del inputs,labels,outputs\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "          if i%100 == 0:\n",
        "            print('Iteration %d loss : %0.2f'%(i,loss.item()))\n",
        "      print('Epoch: %d/%d' % (epoch, epochs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0sXlKk21hp",
        "outputId": "b9bfe6a7-f921-4afa-91d5-a02321d32208"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])"
      ],
      "metadata": {
        "id": "SQhe4Sz0Xcq7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "trainsetSTL = torchvision.datasets.STL10(root='./data', split='train', download=True, transform=transform_train)\n",
        "trainloaderSTL = torch.utils.data.DataLoader(trainsetSTL, batch_size=batch_size, shuffle=True)\n",
        "testsetSTL = torchvision.datasets.STL10(root='./data', split='test', download=True, transform=transform_test)\n",
        "testloaderSTL = torch.utils.data.DataLoader(testsetSTL, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmBgy3OwVWjT",
        "outputId": "f4763992-d39b-4546-c6cd-f104273f88c5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(sqnet,trainloaderSTL,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Dc5fJh-zYlj_",
        "outputId": "67bdccb2-0b7d-4b4b-8417-7f3ac02c82bf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min loss : 2.40\n",
            "Iteration 0 loss : 2.40\n",
            "Min loss : 2.25\n",
            "Min loss : 1.91\n",
            "Min loss : 1.89\n",
            "Min loss : 1.50\n",
            "Iteration 100 loss : 2.16\n",
            "Iteration 200 loss : 2.44\n",
            "Min loss : 1.50\n",
            "Min loss : 1.47\n",
            "Iteration 300 loss : 1.78\n",
            "Min loss : 1.22\n",
            "Iteration 400 loss : 1.79\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-9d94706717dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloaderSTL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, traindata, epochs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}