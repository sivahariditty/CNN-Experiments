{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezNet_Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcC2VcByfYUsAi5yJsQVth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivahariditty/CNN-Experiments/blob/main/SqueezNet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uAlcZwMqjkZB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06U4qzzHneiF",
        "outputId": "4c62709e-a21a-460f-8b74-3ec67da40c0a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((.5,.5,.5),(.5,.5,.5))])"
      ],
      "metadata": {
        "id": "wWOXFIexn6yR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcb-jIuhsRY6",
        "outputId": "a8a83714-4969-4c9f-bf5c-be6e1711411e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG - 16"
      ],
      "metadata": {
        "id": "kkxdUL4iu3jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "T47fonDuu8UE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet = models.squeezenet1_0(pretrained=True)"
      ],
      "metadata": {
        "id": "KDEgSodJvosY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in sqnet.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "prUFB0rB1WS3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))"
      ],
      "metadata": {
        "id": "cJbBptCkwAqW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in sqnet.parameters():\n",
        "  if(param.requires_grad):\n",
        "    print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL7v5Vrq1O1S",
        "outputId": "7023f2ea-345f-42ad-c09d-2d7442dd2ab7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 512, 1, 1])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(dataloader,model):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "81x0f5Io4MhP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqnet = sqnet.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt=optim.SGD(sqnet.parameters(),lr=0.5)"
      ],
      "metadata": {
        "id": "V6gkitWwDqwG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n"
      ],
      "metadata": {
        "id": "QoQ72YN5MqZe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "max_epochs = 16\n",
        "min_loss = 10000\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = sqnet(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if min_loss > loss.item():\n",
        "          min_loss = loss.item()\n",
        "          best_model = copy.deepcopy(sqnet.state_dict())\n",
        "          print(\"Min loss : %0.2f\"%min_loss)\n",
        "        \n",
        "        del inputs,labels,outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        if i%100 == 0:\n",
        "          print('Iteration %d loss : %0.2f'%(i,loss.item()))\n",
        "        \n",
        "    print('Epoch: %d/%d' % (epoch, max_epochs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0sXlKk21hp",
        "outputId": "6a77f724-fa37-4e96-bf38-b155b3d529cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min loss : 2.51\n",
            "Iteration 0 loss : 2.51\n",
            "Min loss : 2.02\n",
            "Min loss : 1.83\n",
            "Min loss : 1.64\n",
            "Min loss : 1.58\n",
            "Min loss : 1.53\n",
            "Min loss : 1.49\n",
            "Min loss : 1.40\n",
            "Iteration 100 loss : 2.41\n",
            "Min loss : 1.26\n",
            "Iteration 200 loss : 1.83\n",
            "Iteration 300 loss : 1.39\n",
            "Iteration 400 loss : 2.09\n",
            "Iteration 500 loss : 1.91\n",
            "Iteration 600 loss : 2.03\n",
            "Iteration 700 loss : 1.88\n",
            "Iteration 800 loss : 2.38\n",
            "Iteration 900 loss : 2.06\n",
            "Iteration 1000 loss : 2.31\n"
          ]
        }
      ]
    }
  ]
}